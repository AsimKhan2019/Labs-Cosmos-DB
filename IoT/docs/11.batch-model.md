# Cosmos DB scenario-based labs - IoT

## 11. Run the predictive maintenance batch scoring model

**Duration**: 20 minutes

<!-- TOC -->
- [Task 1: Import lab notebooks into Azure Synapse Workspace](#task-1-import-lab-notebooks-into-azure-synapse-workspace)
- [Task 2: Run batch scoring notebook](#task-2-run-batch-scoring-notebook)
<!-- /TOC -->

In this exercise, you will import two Synapse notebooks into your Azure Synapse workspace. A notebook is interactive and runs in any web browser, mixing markup (formatted text with instructions), executable code, and outputs from running the code.

Next, you will run the Batch Scoring notebook to make battery failure predictions on vehicles, using vehicle and trip data stored in Cosmos DB.

### Task 1: Import lab notebooks into Azure Synapse Workspace

In this task, you will import the Synapse notebooks into your workspace.

1. In the [Azure portal](https://portal.azure.com), open your lab resource group, then open your **Azure Synapse Service**. There should just one Synapse Workspace resource and its name should start with `synws`.

   ![The Azure Synapse Service is highlighted in the resource group.](./../media/resource-group-synapse.png 'Resource Group')

1. From the Overview section, click on the Workspace web URL. Azure Synapse will automatically sign you in through its Azure Active Directory integration.

   ![Launch Workspace](./../media/synapse-launch-workspace.png 'Launch Workspace')

1. Select **Develop**, select **Notebooks**, and click on actions **...** and select Import

   ![The Import link is highlighted in the Workspace.](./../media/synapse-import-link.png 'Workspace')

1. Navigate to your **deploy** folder and select the file called **Batch_Scoring.ipynb**, then select **Open**.

   ![The URL has been entered in the import form.](./../media/synapse-import.png 'Import Notebooks')

    Repeat the process for the file called **Model_Deployment.ipynb**. You will use this file later.

1. After importing, you will see the two new notebooks under the **Notebooks** section.

### Task 2: Run batch scoring notebook

In this task, you will run the `Batch_Scoring` notebook, using a pre-trained machine learning (ML) model to determine if the battery needs to be replaced on several vehicles within the next 30 days.

The code leverages the Azure Cosmos DB Analytical Store. This allows the Spark pool to read the data directly from the analytical storage, without having o use any container RUs. It also gives us the ability to join data across containers.

The notebook performs the following actions:

1. Downloads a pre-trained ML model, saves it to Azure ML, then uses that model for batch scoring.
1. Uses the Cosmos DB Analytical Store connector to retrieve completed Trips and Vehicle metadata from the `metadata` Cosmos DB analytical container, prepares the data using SQL queries, then surfaces the data as temporary views.
1. Applies predictions against the data, using the pre-trained model.
1. Uses the Cosmos DB Spark connector to saves the prediction results back into the Cosmos DB `maintenance` container for reporting purposes.

To run this notebook, perform the following steps:

1. Select the **Batch_Scoring** notebook to open it.

   ![The Batch Scoring notebook is highlighted.](./../media/synapse-batch-scoring-notebook.png 'Batch_Scoring Notebook highlighted')

1. Before you can execute the cells in this or the other notebooks for this lab, you must first attach it to a Spark pool cluster. Expand the dropdown at the top of the notebook where you see **Attach to** and select your Spark pool. Make sure to select PySpark as Language.

   ![The screenshot displays the lab cluster selected for attaching to the notebook.](./../media/synapse-notebook-attach-cluster.png 'Attach cluster')

1. You may use keyboard shortcuts to execute the cells, such as **Ctrl+Enter** to execute the current cell, or **Shift+Enter** to execute a cell and move to the next one below.

In both notebooks, you will be required to provide values for your Machine Learning service workspace. You can find these values within the Overview blade of your Machine Learning service workspace that is located in your lab resource group.

The values highlighted in the screenshot below are for the following variables in the notebooks:

1. `subscription_id`
1. `resource_group`
1. `workspace_name`
1. `workspace_region`

![The required values are highlighted.](./../media/machine-learning-workspace-values.png "Machine Learning service workspace values")

> If you wish to execute this notebook on a scheduled basis, such as every evening, you can add the Notebook to an existing or new **Pipeline**.

[Return to Table of Contents to continue](./README.md)
