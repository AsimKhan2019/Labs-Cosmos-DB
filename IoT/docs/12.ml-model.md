# Cosmos DB scenario-based labs - IoT

## 12. Create an Azure Machine Learning (ML) Model to Predict whether Maintenance will be needed in the next 30 days

**Duration**: 60 minutes

<!-- TOC -->
- [Task 1: Create a Service Principal and Role Assignment](#task-1-create-a-service-principal-and-role-assignment)
- [Task 2: Access the Azure ML Studio](#task-2-access-the-azure-ml-studio)
- [Task 3: Provision Azure ML Compute Resources](#task-3-provision-azure-ml-compute-resources)
- [Task 4: Create Datastore and Dataset](#task-4-create-datastore-and-dataset)
- [Task 5: Create Azure ML Model and select Compute Target](#task-5-create-azure-ml-model-and-select-compute-target)
- [Task 6: Build Model in Azure ML Designer](#task-6-build-model-in-azure-ml-designer)
<!-- /TOC -->

In this exercise, you will create an Azure Machine Learning (ML) model using the visual Azure ML Designer, then deploy batch and real-time inferencing pipelines. Then you will expose the real-time inferencing pipeline via a REST API endpoint.

### Task 1: Create a Service Principal and Role Assignment

In this task, you will create a Service Principal and a Role Assignment to allow the Service Principal access to the data you exported from Cosmos DB to Azure Data Lake Store in the preceding Exercise. The Azure ML model you will build below will use this Service Principal to work with the data from Cosmos DB.

In previous Exercises, you worked with Role Assignments in the Azure portal. This task could be done in the same way, but this time, you will instead use the Azure Cloud Shell and Azure Command Line Interface (CLI) commands.

To start, you will need three pieces of information. Note these from your Resource Group for use below:

   1. The Resource Group name
   2. The Azure subscription ID
   3. The Synapse storage account name - this starts with "synsa"

![Get info from the portal.](../media/aml-sp-info-portal.png 'Get info from the portal.')

Next, open the Cloud Shell from the top right navigation bar. If prompted, select a Bash shell.

![Open the Cloud Shell.](../media/cloud-shell.png 'Open the Cloud Shell.')

**NOTE**: the following commands will NOT work if you are in a Powershell shell. Make sure you are in a Bash shell!

First, run the following Azure CLI commands to set the three pieces of information you noted above to variables.

```
subscription_id="YOUR_SUBSCRIPTION_ID_BETWEEN_THESE_QUOTES"
resource_group="YOUR_RESOURCE_GROUP_NAME_BETWEEN_THESE_QUOTES"
storage_acct_name="YOUR_STORAGE_ACCOUNT_NAME_BETWEEN_THESE_QUOTES"
```

Next, run the following Azure CLI command to retrieve the full Resource ID for your Synapse storage account and store it in a variable. Optionally, you can run the echo command to verify that you retrieved the storage account Resource ID correctly.

```
storage_acct_id="$(az storage account show --subscription $subscription_id -g $resource_group -n $storage_acct_name -o tsv --query id)"

echo $storage_acct_id
```

![Set variables and retrieve storage account Resource ID at the Cloud Shell.](../media/cloud-shell2.png 'Set variables and retrieve storage account Resource ID at the Cloud Shell.')

In addition to the three pieces of information you noted above, you will need to provide a unique name for the Service Principal. For example, you could append "-ml-access" to the Synapse storage account name.

```
sp_name="$storage_acct_name""-ml-access"
```

Next, you will run an Azure CLI command to create a new Service Principal and assign it the "Storage Blob Data Contributor" role on the Synapse storage account.

**NOTE**: IMPORTANT! You will need to note information from the output of the next command. There is no way to retrieve this information later.

```
az ad sp create-for-rbac -n "$sp_name" --role "Storage Blob Data Contributor" --scopes "$storage_acct_id"
```

Note the following two pieces of information from the output: *appId* and *password*. You will need these later in this Exercise.

![Create Service Principal and retrieve appId and password values for later use.](../media/cloud-shell3.png 'Create Service Principal and retrieve appId and password values for later use.')

When you have safely stored the appId and password values for later use, you can close the Cloud Shell and continue this Exercise.

### Task 2: Access the Azure ML Studio

In your Resource Group, select the Azure Machine Learning resource.

![Select the Machine Learning resource.](../media/aml-rg.png 'Select the Machine Learning resource.')

On the Overview blade, navigate to the ML Studio by selecting either the "Studio web URL" or the "Launch studio" button.

![Navigate to the ML Studio.](../media/aml-overview.png 'Navigate to the ML Studio.')

![Azure ML Studio Home.](../media/aml-studio.png 'Azure ML Studio Home.')

### Task 3: Provision Azure ML Compute Resources

>**NOTE: IF YOU USED THE DEMO DEPLOYMENT, SKIP THIS TASK - CONTINUE WITH [TASK 4](#task-4-create-datastore-and-dataset)**

In this task, you will provision compute resources for Azure ML training and real-time inferencing.

The trained model will be deployed to the real-time inferencing compute resource, where it will expose a REST endpoint that the web app will call to get maintenance predictions.

In the left navigation bar, select **Compute**. Select the **Compute clusters** tab. Then select **+New**.

![Create a new Compute cluster for training.](../media/aml-compute-train1.png 'Create a new Compute cluster for training.')

Enter a name for the compute resource, such as "ml-train". Enter a maximum number of compute nodes. A maximum of 1 is adequate for this task. Then select **Create**. The compute resource will take a few minutes to deploy. You can continue working while it deploys.

![Configure new Compute cluster for training.](../media/aml-compute-train2.png 'Configure new Compute cluster for training.')

Next, select the **Inference clusters** tab. Then select **+New**.

![Create a new real-time inference cluster.](../media/aml-compute-inf1.png 'Create a new real-time inference cluster.')

Enter a name for the compute resource, such as "ml-inf". The remaining defaults should be adequate, though you may need to select an Azure region with available quota for the needed Virtual Machine sizes.

Then select **Create**. The compute resource will take a few minutes to deploy. You can continue working while it deploys.

![Configure new Compute cluster for inference.](../media/aml-compute-inf2.png 'Configure new Compute cluster for inference.')

After a few minutes, the **Compute clusters** and **Inference clusters** tabs will show the completed provisioning of the compute resources. You can continue with the next task while the compute resources are still provisioning.

![Completed compute resources.](../media/aml-compute-completed.png 'Completed compute resources.')

### Task 4: Create Datastore and Dataset

In this task, you will connect the ML Model to the data you prepared and stored in Azure Data Lake Storage in the previous Exercise.

First, create a Datastore. Select **Datastores**, **+ New datastore**.

![Create new Datastore.](../media/aml-datastore1.png 'Create new Datastore.')

On the new datastore blade, provide the following values.

- Datastore name: note what you enter here for later reference.
- Datastore type: select **Azure Data Lake Storage Gen2**.
- Store name: select the storage account whose name begins with **synsa**. Confirm the Resource Group (in parentheses) matches where you are working.
- Azure Data Lake Gen2 file system name: select **workspace**, which was created for you.
- Client ID: provide the **appId** value from step 1 above.
- Client secret: provide the **password** value from step 1 above.

Select **Create**.

![Create new Datastore.](../media/aml-datastore2.png 'Create new Datastore.')

The datastore will be created and displayed.

![New Datastore created.](../media/aml-datastore3.png '[New Datastore created.')

Next, you will create a Dataset so that Azure ML can access the data from the previous Exercise.

Select **Datasets**, **Registered datasets**, **+ Create dataset**, and **From datastore**.

![Create new dataset.](../media/aml-dataset1.png 'Create new dataset.')

Enter "maintenance-raw" for the dataset Name, and select "Tabular" for Dataset type. Then select **Next**.

![Create new dataset.](../media/aml-dataset2.png 'Create new dataset.')

On Datastore selection, select **Previously created datastore**, then select the datastore you created above. Then select **Select datastore**.

![Create new dataset.](../media/aml-dataset3.png 'Create new dataset.')

In **Path**, enter the path to which you wrote output data in the Synapse notebook in the previous exercise. Enter **lab-data/raw/**, or if you changed the output path in the Synapse notebook, enter the path you used. Then select **Next**.

![Create new dataset.](../media/aml-dataset4.png 'Create new dataset.')

A preview of the data will be shown to verify that the settings are correct. Select **Next**.

![Create new dataset.](../media/aml-dataset5.png 'Create new dataset.')

Do not change Schema settings. Select **Next**.

![Create new dataset.](../media/aml-dataset6.png 'Create new dataset.')

Confirm settings and select **Create**.

![Create new dataset.](../media/aml-dataset7.png 'Create new dataset.')

After the dataset is created, it will be shown.

![New dataset created.](../media/aml-dataset8.png 'New dataset created.')

### Task 5: Create Azure ML Model and select Compute Target

In this task, you will use the Azure ML Studio Designer to build a model in the interactive graphic editor. You will use several Azure ML Designer modules. For details, see the [Azure ML Designer documentation](https://docs.microsoft.com/azure/machine-learning/algorithm-module-reference/module-reference).

In the Azure ML Studio, select **Designer**, then **New pipeline +**.

![Create new pipeline.](../media/aml-studio-designer-new.png 'Create new pipeline.')

In the new pipeline, provide a meaningful name instead of the default.

![Provide pipeline name.](../media/aml-studio-pipeline-name.png 'Provide pipeline name.')

Note the warning to select a compute target to run the pipeline. Select **Select compute target**.

![Select compute target.](../media/aml-studio-pipeline-train-target.png 'Select compute target.')

Select the existing training cluster. If you followed the demo deployment, this was created for you. If you followed the lab path, you created this training cluster in Task 2, above. Then select **Save**.

![Select compute target.](../media/aml-studio-pipeline-train-target2.png 'Select compute target.')

### Task 6: Build Model in Azure ML Designer

You will now build the model pipeline by dragging Azure ML components onto the design surface, configuring each as described below, and connecting them in order.

1. Expand **Datasets**. Find the dataset you created above in Task 4. Drag it onto the design surface.

![Drag dataset onto the design surface.](../media/aml-design01.png 'Drag dataset onto the design surface.')

2. Expand **Data Transformation**. Drag **Apply SQL Transformation** onto the design surface. Connect the dataset's bottom node to the left top node of **Apply SQL Transformation**.

![Add Apply SQL Transformation.](../media/aml-design02.png 'Add Apply SQL Transformation.')

Select the **Apply SQL Transformation** node. In its configuration area, replace the existing SQL query with the following query:

```
SELECT  vin,
        batteryAgeDays, 
        batteryRatedCycles, 
        lifetimeBatteryCyclesUsed,
        tripDurationMinutes, 
        CASE WHEN lifetimeBatteryCyclesUsed + (30 * lifetimeBatteryCyclesUsed / batteryAgeDays) >= batteryRatedCycles THEN 1 ELSE 0 END as maint_needed
FROM    t1
```

This query selects fields from the input data (which you wrote to Azure Data Lake Store from a Synapse notebook in the previous Exercise). It also adds a calculated field **maint_needed**, which will be used to train the ML model later in this Task.

The **maint_needed** field is calculated by adding 30 times the average daily battery cycles used to the current battery cycles used, and setting **maint_needed** to true if the calculated value exceeds the rated battery cycles.

![Configure Apply SQL Transformation.](../media/aml-design03.png 'Configure Apply SQL Transformation.')

Before adding more components to the design surface, you will now submit an initial run of the model to verify functionality. Select **Submit**.

![Submit initial run.](../media/aml-design04.png 'Submit initial run.')

On **Set up pipeline run**, select to **Create new** Experiment. Enter an experiment name, then select **Submit**.

![Set up initial run.](../media/aml-design05.png 'Set up initial run.')

You can track the progress of the run by selecting **View run overview**. You can also continue working on this Task while the run executes.

3. Drag **Edit Metadata** onto the design surface and connect the bottom output of **Apply SQL Transformation** to the top input of **Edit Metadata**.

![Add Edit Metadata.](../media/aml-design06.png 'Add Edit Metadata.')

On the **Edit Metadata** configuration area, select **Edit column**.

![Configure Edit Metadata.](../media/aml-design07.png 'Configure Edit Metadata.')

Enter **vin** for the column, then select **Save**.

![Configure Edit Metadata.](../media/aml-design08.png 'Configure Edit Metadata.')

Now, change the value for **Categorical** from its default _Unchanged_ to the correct value, **Categorical**. Doing this marks the **vin** field as a categorical field for the ML algorithm.

![Configure Edit Metadata.](../media/aml-design09.png 'Configure Edit Metadata.')

Run the model again by selecting **Submit** at the top right of the design surface.

4. Drag another **Edit Metadata** onto the design surface. Connect the bottom output of the previous **Edit Metadata** to the top input of this one.

![Add another Edit Metadata.](../media/aml-design09a.png 'Add another Edit Metadata.')

Configure the second **Edit Metadata**. Select these two columns: **lifetimeBatterCyclesUsed**, **tripDurationMinutes**. Then set **Fields** to **Features**.

This step designates these two fields in the input dataset for the ML algorithm to use as inputs.

![Configure another Edit Metadata.](../media/aml-design09b.png 'Configure another Edit Metadata.')

5. Drag **Split Data** onto the design surface and connect the bottom output of the second **Edit Metadata** to the top input of **Split Data**.

![Add Split Data.](../media/aml-design10.png 'Add Split Data.')

This step splits the input dataset into two parts: one part used to train the ML algorithm, and one part used to evaluate the trained algorithm's performance. On the **Split Data** configuration area, set **Fraction of rows in the first output dataset** to 0.7. This means that 70% of the input dataset will be used for algorithm training.

![Configure Split Data.](../media/aml-design11.png 'Configure Split Data.')

6. Drag **Two-Class Boosted Decision Tree** and **Train Model** onto the design surface.

Place **Two-Class Boosted Decision Tree** to the left of **Split Data** which you dragged on in the previous step.

Place **Train Model** underneath, and between, **Two-Class Boosted Decision Tree** and **Split Data**.

Connect the bottom output of **Two-Class Boosted Decision Tree** to the left top input of **Train Model**.

Connect the left bottom output of **Split Data** to the right top input of **Train Model**.

This connects the training data you configured in the previous step to the ML algorithm chosen. Note that you can experiment with other binary classifiers available in Azure ML Designer; see the algorithm selectors for links to technical discussion of each algorithm.

![Add and Connect ML algorithm and Train Model.](../media/aml-design12.png 'Add and Connect ML algorithm and Train Model.')

Select **Train Model**, then **Edit column**. Select **maint_needed**, which you added to the dataset in the **Apply SQL Transformation** step above. This designates which column is the _label_, or the result to predict: in this case, whether maintenance will be required in the next 30 days or not.

(If you do not see **maint_needed** in the available columns, re-run the experiment by selecting **Submit** at the top right of the design surface.)

![Configure Train Model.](../media/aml-design13.png 'Configure Train Model.')

7. Drag **Score Model** onto the design surface.

Connect the bottom output of **Train Model** to the top left input of **Score Model**.

Connect the bottom right output of **Split Data** to the top right input of **Score Model**.

This step uses the other dataset output from **Split Data** to evaluate the trained algorithm's performance against test data it did not see during training.

![Add Score Model.](../media/aml-design14.png 'Add Score Model.')

***
**IMPORTANT** You should now run the model by selecting **Submit** at the top right of the design surface, so that the remaining steps can see the outputs of the above steps. In particular, **Score Model** will add a column you will need below.
***

When the model run completes, you can visualize the scored dataset. In particular, you can compare the model's predictions to the calculated **maint_needed** column added earlier in this Exercise.

Right-click **Score Model**. In the context menu, select **Visualize** > **Scored dataset**.

![Visualize Scored Dataset.](../media/aml-design15.png 'Visualize Scored Dataset.')

In the scored dataset view, scroll right and compare the values for **maint_needed** and **Scored Labels**, which was generated by the ML algorithm. Note where both columns contain a value of **1**, indicating that maintenance will be needed.

![Visualize Scored Dataset.](../media/aml-design16.png 'Visualize Scored Dataset.')

8. Drag **Select Columns in Dataset** to the design surface.

Place it under and to the left of **Score Model**. Connect the bottom output of **Score Model** to the top input of **Select Columns in Dataset**.

![Add Select Columns in Dataset.](../media/aml-design17.png 'Add Select Columns in Dataset.')

Configure **Add Select Columns in Dataset** to only select the columns we will need later. Select **Edit column**, then select these columns: **vin**, **batteryAgeDays**, **batteryRatedCycles**, **lifetimeBatteryCyclesUsed**, **tripDurationMinutes**, **Scored Labels**.

![Configure Select Columns in Dataset.](../media/aml-design18.png 'Configure Select Columns in Dataset.')

9. Drag **Edit Metadata** to the design surface. Place it below the **Select Columns in Dataset** you just configured. Connect the bottom output of **Select Columns in Dataset** to the top input of **Edit Metadata**.

![Add Edit Metadata.](../media/aml-design19.png 'Add Edit Metadata.')

Select **Edit column**, then select the **Scored Labels** column. In **New column names**, enter **result**.

This renames the **Scored Labels** column name to **result**, which is the name that the web app will look for when calling the operationalized ML model for a prediction.

![Configure Edit Metadata.](../media/aml-design20.png 'Configure Edit Metadata.')

10. **OPTIONAL** This step is not needed for later Exercises, but you can do it to gain further insight into the performance of the ML algorithm used earlier in this Exercise.

Drag **Evaluate Model** onto the design surface. Place it below and to the right of **Score Model**. Connect the bottom output of **Score Model** to the top left input of **Evaluate Model**.

![Add Evaluate Model.](../media/aml-design21.png 'Add Evaluate Model.')

11. The model is now complete. Select **Submit** at the top right of the design surface and wait for the model to complete running.

If you added **Evaluate Model** in the previous optional step, you can now inspect model performance. Select **Evaluate Model**, right-click, and on the context menu select **Visualize** > **Evaluation results**. Consult the Azure ML documentation for how to interpret the results.

![Inspect Evaluate Model.](../media/aml-design22.png 'Inspect Evaluate Model.')

***

Once the run completes, the model should look similar to the following. Note that the following screenshot shows all steps having successfully completed, and includes the optional **Evaluate Model** from step 10.

![Completed Model.](../media/aml-design-complete.png 'Completed Model.')

***

This exercise is now completed and you can continue with the next exercise.

[Return to Table of Contents to continue](./README.md)
