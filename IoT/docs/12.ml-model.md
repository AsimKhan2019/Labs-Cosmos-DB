# Cosmos DB scenario-based labs - IoT

## 12. Create an Azure Machine Learning (ML) Model to Predict whether Maintenance will be needed in the next 30 days

**Duration**: 60 minutes

<!-- TOC -->
- [Task 1: Create a Service Principal and Role Assignment](#task-1-create-a-service-principal-and-role-assignment)
- [Task 2: Access the Azure ML Studio](#task-2-access-the-azure-ml-studio)
- [Task 3: Provision Azure ML Compute Resources](#task-3-provision-azure-ml-compute-resources)
- [Task 4: Create Datastore and Dataset](#task-4-create-datastore-and-dataset)
- [Task 5: Create Azure ML Model](#task-5-create-azure-ml-model)
- [Task 6: Build Model in Azure ML Designer](#task-6-build-model-in-azure-ml-designer)
<!-- /TOC -->

In this exercise, you will create an Azure Machine Learning (ML) model using the visual Azure ML Designer, then deploy batch and real-time inferencing pipelines. Then you will expose the real-time inferencing pipeline via a REST API endpoint.

### Task 1: Create a Service Principal and Role Assignment

In this task, you will create a Service Principal and a Role Assignment to allow the Service Principal access to the data you exported from Cosmos DB to Azure Data Lake Store in the preceding Exercise. The Azure ML model you will build below will use this Service Principal to work with the data from Cosmos DB.

In previous Exercises, you worked with Role Assignments in the Azure portal. This task could be done in the same way, but this time, you will instead use the Azure Cloud Shell and Azure Command Line Interface (CLI) commands.

To start, you will need three pieces of information. Note these from your Resource Group for use below:

   1. The Resource Group name
   2. The Azure subscription ID
   3. The Synapse storage account name - this starts with "synsa"

![Get info from the portal.](../media/aml-sp-info-portal.png 'Get info from the portal.')

Next, open the Cloud Shell from the top right navigation bar. If prompted, select a Bash shell.

![Open the Cloud Shell.](../media/cloud-shell.png 'Open the Cloud Shell.')

**NOTE**: the following commands will NOT work if you are in a Powershell shell. Make sure you are in a Bash shell!

First, run the following Azure CLI commands to set the three pieces of information you noted above to variables.

```
subscription_id="YOUR_SUBSCRIPTION_ID_BETWEEN_THESE_QUOTES"
resource_group="YOUR_RESOURCE_GROUP_NAME_BETWEEN_THESE_QUOTES"
storage_acct_name="YOUR_STORAGE_ACCOUNT_NAME_BETWEEN_THESE_QUOTES"
```

Next, run the following Azure CLI command to retrieve the full Resource ID for your Synapse storage account and store it in a variable. Optionally, you can run the echo command to verify that you retrieved the storage account Resource ID correctly.

```
storage_acct_id="$(az storage account show --subscription $subscription_id -g $resource_group -n $storage_acct_name -o tsv --query id)"

echo $storage_acct_id
```

![Set variables and retrieve storage account Resource ID at the Cloud Shell.](../media/cloud-shell2.png 'Set variables and retrieve storage account Resource ID at the Cloud Shell.')

In addition to the three pieces of information you noted above, you will need to provide a unique name for the Service Principal. For example, you could append "-ml-access" to the Synapse storage account name.

```
sp_name="$storage_acct_name""-ml-access"
```

Next, you will run an Azure CLI command to create a new Service Principal and assign it the "Storage Blob Data Contributor" role on the Synapse storage account.

**NOTE**: IMPORTANT! You will need to note information from the output of the next command. There is no way to retrieve this information later.

```
az ad sp create-for-rbac -n "$sp_name" --role "Storage Blob Data Contributor" --scopes "$storage_acct_id"
```

Note the following two pieces of information from the output: *appId* and *password*. You will need these later in this Exercise.

![Create Service Principal and retrieve appId and password values for later use.](../media/cloud-shell3.png 'Create Service Principal and retrieve appId and password values for later use.')

When you have safely stored the appId and password values for later use, you can close the Cloud Shell and continue this Exercise.

### Task 2: Access the Azure ML Studio

In your Resource Group, select the Azure Machine Learning resource.

![Select the Machine Learning resource.](../media/aml-rg.png 'Select the Machine Learning resource.')

On the Overview blade, navigate to the ML Studio by selecting either the "Studio web URL" or the "Launch studio" button.

![Navigate to the ML Studio.](../media/aml-overview.png 'Navigate to the ML Studio.')

![Azure ML Studio Home.](../media/aml-studio.png 'Azure ML Studio Home.')

### Task 3: Provision Azure ML Compute Resources

>**NOTE: IF YOU USED THE DEMO DEPLOYMENT, SKIP THIS TASK - CONTINUE WITH [TASK 3](#task-3-azure-ml-experiment)**

In this task, you will provision compute resources for Azure ML training and real-time inferencing.

The trained model will be deployed to the real-time inferencing compute resource, where it will expose a REST endpoint that the web app will call to get maintenance predictions.

In the left navigation bar, select **Compute**. Select the **Compute clusters** tab. Then select **+New**.

![Create a new Compute cluster for training.](../media/aml-compute-train1.png 'Create a new Compute cluster for training.')

Enter a name for the compute resource, such as "ml-train". Enter a maximum number of compute nodes. A maximum of 1 is adequate for this task. Then select **Create**. The compute resource will take a few minutes to deploy. You can continue working while it deploys.

![Configure new Compute cluster for training.](../media/aml-compute-train2.png 'Configure new Compute cluster for training.')

Next, select the **Inference clusters** tab. Then select **+New**.

![Create a new real-time inference cluster.](../media/aml-compute-inf1.png 'Create a new real-time inference cluster.')

Enter a name for the compute resource, such as "ml-inf". The remaining defaults should be adequate, though you may need to select an Azure region with available quota for the needed Virtual Machine sizes.

Then select **Create**. The compute resource will take a few minutes to deploy. You can continue working while it deploys.

![Configure new Compute cluster for inference.](../media/aml-compute-inf2.png 'Configure new Compute cluster for inference.')

After a few minutes, the **Compute clusters** and **Inference clusters** tabs will show the completed provisioning of the compute resources. You can continue with the next task while the compute resources are still provisioning.

![Completed compute resources.](../media/aml-compute-completed.png 'Completed compute resources.')

### Task 4: Create Datastore and Dataset

In this task, you will connect the ML Model to the data you prepared and stored in Azure Data Lake Storage in the previous Exercise.

First, create a Datastore. Select **Datastores**, **+ New datastore**.

![Create new Datastore.](../media/aml-datastore1.png 'Create new Datastore.')

On the new datastore blade, provide the following values.

- Datastore name: note what you enter here for later reference.
- Datastore type: select **Azure Data Lake Storage Gen2**.
- Store name: select the storage account whose name begins with **synsa**. Confirm the Resource Group (in parentheses) matches where you are working.
- Azure Data Lake Gen2 file system name: select **workspace**, which was created for you.
- Client ID: provide the **appId** value from step 1 above.
- Client secret: provide the **password** value from step 1 above.

Select **Create**.

![Create new Datastore.](../media/aml-datastore2.png 'Create new Datastore.')

The datastore will be created and displayed.

![New Datastore created.](../media/aml-datastore3.png '[New Datastore created.')

Next, you will create a Dataset so that Azure ML can access the data from the previous Exercise.

Select **Datasets**, **Registered datasets**, **+ Create dataset**, and **From datastore**.

![Create new dataset.](../media/aml-dataset1.png 'Create new dataset.')

Enter "maintenance-raw" for the dataset Name, and select "Tabular" for Dataset type. Then select **Next**.

![Create new dataset.](../media/aml-dataset2.png 'Create new dataset.')

On Datastore selection, select **Previously created datastore**, then select the datastore you created above. Then select **Select datastore**.

![Create new dataset.](../media/aml-dataset3.png 'Create new dataset.')

In **Path**, enter the path to which you wrote output data in the Synapse notebook in the previous exercise. Enter **lab-data/raw/**, or if you changed the output path in the Synapse notebook, enter the path you used. Then select **Next**.

![Create new dataset.](../media/aml-dataset4.png 'Create new dataset.')

A preview of the data will be shown to verify that the settings are correct. Select **Next**.

![Create new dataset.](../media/aml-dataset5.png 'Create new dataset.')

Do not change Schema settings. Select **Next**.

![Create new dataset.](../media/aml-dataset6.png 'Create new dataset.')

Confirm settings and select **Create**.

![Create new dataset.](../media/aml-dataset7.png 'Create new dataset.')

After the dataset is created, it will be shown.

![New dataset created.](../media/aml-dataset8.png 'New dataset created.')

### Task 5: Create Azure ML Model

In this task, you will use the Azure ML Studio Designer to build a model in the interactive graphic editor.

In the Azure ML Studio, select **Designer**, then **New pipeline +**.

![Create new pipeline.](../media/aml-studio-designer-new.png 'Create new pipeline.')

In the new pipeline, provide a meaningful name instead of the default.

![Provide pipeline name.](../media/aml-studio-pipeline-name.png 'Provide pipeline name.')

Note the warning to select a compute target to run the pipeline. Select **Select cmpute target**.

![Select compute target.](../media/aml-studio-pipeline-train-target.png 'Select compute target.')

Select the existing training cluster. If you followed the demo deployment, this was created for you. If you followed the lab path, you created this training cluster in Task 2, above. Then select **Save**.

![Select compute target.](../media/aml-studio-pipeline-train-target2.png 'Select compute target.')

### Task 6: Build Model in Azure ML Designer

In this task, you will build the ML model on the design surface. You will use several Azure ML Designer modules. For details, see the [Azure ML Designer documentation](https://docs.microsoft.com/azure/machine-learning/algorithm-module-reference/module-reference).



