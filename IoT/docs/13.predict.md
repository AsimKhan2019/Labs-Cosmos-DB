# Cosmos DB scenario-based labs - IoT

## 13. Run batch and real-time predictions

**Duration**: 45 minutes

<!-- TOC -->
- [Task 1: Deploy Batch Inference Pipeline](#task-1-deploy-batch-inference-pipeline)
- [Task 2: Perform Batch Score and write Scored Data back to Cosmos DB](#task-2-perform-batch-score-and-write-scored-data-back-to-cosmos-db)
- [Task 3: Deploy Real Time Inference Pipeline](#task-3-deploy-real-time-inference-pipeline)
- [Task 4: Configure Web App to call Real Time Inference Endpoint](#task-4-configure-web-app-to-call-real-time-inference-endpoint)
<!-- /TOC -->

In this Exercise, you will deploy batch and real-time inferencing endpoints for the ML model you trained in the previous Exercise.

Then you will use the batch inferencing endpoint to perform a batch prediction on the vehicles dataset, and write the predictions back to Cosmos DB.

Then you will configure the web app to call the real-time inferencing endpoint via a REST API call, enabling the real-time predictive capability on the vehicle details view.

### Task 1: Deploy Batch Inference Pipeline

At the top right of the Azure ML design surface, select **Create inference pipeline** > **Batch inference pipeline**.

![Create batch inference pipeline.](../media/aml-infer01.png 'Create batch inference pipeline.')

**IMPORTANT** Ensure you are on the **Batch inference pipeline** tab in the Azure ML Designer.

![Designer batch inference pipeline.](../media/aml-infer01a.png 'Designer batch inference pipeline.')

Drag **Export Data** onto the design surface. Place it below the final **Edit Metadata**. Connect the bottom output of **Edit Metadata** to the top input of **Export Data**.

![Add Export Data.](../media/aml-infer02.png 'Add Export Data.')

Configure **Export Data**.

Select **Datastore type** as **Azure Data Lake Storage Gen2**.

Select **Datastore** and set it to **synsa**.

In **Path**, enter `lab-data/scored/scored.batch.parquet`.

Select **File format** and set it to **Parquet**.

![Configure Export Data.](../media/aml-infer03.png 'Configure Export Data.')

Now, at the top right of the design surface, select **Submit** and wait for the run to complete.



### Task 2: Perform Batch Score and write Scored Data back to Cosmos DB

### Task 3: Deploy Real Time Inference Pipeline

### Task 4: Configure Web App to call Real Time Inference Endpoint

